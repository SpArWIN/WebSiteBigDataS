import { useEffect, useState } from "react";
import { useLocation } from "react-router-dom";
import { Parallax, ParallaxProvider } from "react-scroll-parallax";

const ParallaxText = () => {

       const location = useLocation();
    const [highlightedSection, setHighlightedSection] = useState('');

        useEffect(() => {
        const params = new URLSearchParams(location.search);
        const highlight = params.get('highlight');
        if (highlight) {
            setHighlightedSection(highlight);
            setTimeout(() => {
                setHighlightedSection(''); // Сбросить выделение через некоторое время
            }, 5000);
        }
    }, [location]);
  return (
    <ParallaxProvider>
      <div >
        <Parallax speed={2}>
          <div className='plush '>
            <h1 style={{ textAlign: "center" }}>Обработка больших данных</h1>
            <ul>
              <li>
                <h2 style={{ textAlign: "center", fontSize: 30 }}>Введение </h2>
              </li>
            </ul>
            <p>
              В современном мире мы генерируем огромные объемы данных, которые
              называют большими данными (Big Data). Это разнообразные
              информационные потоки, поступающие из различных источников, таких
              как интернет, <strong>социальные сети</strong>, датчики, системы видеонаблюдения и
              др. Обработка больших данных открывает новые возможности для
              бизнеса, науки и общества в целом, позволяя получать ценные
              инсайты, прогнозировать тренды и принимать более эффективные
              решения.
            </p>
            <p>
              Однако обработка больших данных сопряжена с рядом сложностей,
              которые необходимо учитывать при разработке и внедрении
              соответствующих технологий.
            </p>
          
          </div>
        </Parallax>
        <Parallax speed={-2}>
            <div style={{marginBottom:10}} className="plush">
            <h2>Ключевые характеристики больших данных</h2>
                          <ul>
            <li><strong>Объем</strong> (Volume): Огромное количество данных.</li>
            <li>
             <strong>Скорость</strong>(Velocity): Высокая скорость поступления и обработки
              данных.
            </li>
            <li>
             <strong>Разнообразие</strong> (Variety): Разнообразные типы данных, включая
              структурированные, полуструктурированные и неструктурированные.
            </li>
            <li>
              <strong>Достоверность</strong> (Veracity): Качество данных, включая точность,
              полноту и актуальность.
            </li>
          </ul>
            </div>
               
        </Parallax>
        <Parallax speed={-2} >
            <div className="plush">
            <ul>
                <li>
                   <h2 style={{textAlign:"center", fontFamily:'Montserrat'}}>Вызовы обработки больших данных</h2>
                </li>
              </ul>

            <h3 style={{ backgroundColor: highlightedSection === 'section1' ? 'yellow' : 'transparent' }} id="section1">1. Хранение данных</h3>
          <p  >
            Хранение огромных объемов данных требует специализированных
            систем хранения, которые могут быть дорогими и сложными в
            обслуживании.
          </p>
          <p id="section1" style={{ backgroundColor: highlightedSection === 'section1' ? 'yellow' : 'transparent' }}>
            Обучение аналитических моделей, особенно нейронных сетей, может
            занимать много времени и ресурсов. Например, для создания моделей,
            способных генерировать изображения на основе текстовых описаний,
            требуется обработка массивов данных размером в сотни терабайт. Это
            требует не только времени, но и мощных вычислительных ресурсов, что
            может быть недоступно для малых и средних предприятий.

          </p>
 
           <h3>3. Разнообразие форматов данных</h3>
          <p>
            Данные могут поступать в различных форматах: структурированные,
            полуструктурированные и неструктурированные. Это создает сложности в
            их интеграции и анализе. Необходимость обработки данных из
            различных источников требует использования сложных ETL-процессов
            (Extract, Transform, Load), что увеличивает время и затраты на
            подготовку данных.
          </p>
          <h3>4. Обработка в реальном времени</h3>
          <p>
            В некоторых приложениях, таких как финансовые рынки или системы
            мониторинга, требуется обработка данных в реальном времени. Это
            требует высокопроизводительных систем и алгоритмов, способных
            быстро реагировать на изменения. Разработка таких систем требует
            значительных усилий и ресурсов.
          </p>
          <h3>5. Качество данных</h3>
          <p>
            Большие объемы данных часто содержат ошибки, дубликаты и
            пропуски. Обеспечение качества данных является критически важной
            задачей, так как низкое качество данных может привести к неверным
            выводам и решениям. Необходимость в очистке и валидации данных
            требует дополнительных затрат времени и ресурсов.
          </p>

            </div>
              

        </Parallax>
        <Parallax>
            <div className="plush">
                
            <ul>
                <li>
                   <h2  id="section2" style={{textAlign:"center" , backgroundColor: highlightedSection ==='section2'? 'orange': 'transparent'}}>СПОСОБЫ ОБРАБОТКИ ДАННЫХ</h2>
                </li>
            </ul>
            <p id="section2" style={{textAlign:"center" , backgroundColor: highlightedSection ==='section2'? 'orange': 'transparent'}} >Обработка больших объёмов данных требует использования специализированных технологий и инструментов. К основным из них относятся:</p>
                <ol>
  <li><strong>Hadoop:</strong> это фреймворк, который позволяет распределять обработку данных по кластерам. Он включает в себя <strong>Hadoop Distributed File System (HDFS)</strong> для хранения данных и <strong>MapReduce</strong> для их обработки.</li>
    <li><strong>Spark:</strong> это мощная платформа для обработки данных в памяти, которая обеспечивает более быструю обработку по сравнению с Hadoop. Spark поддерживает различные языки программирования, такие как <strong>Scala</strong>, <strong>Python</strong> и <strong>Java</strong>.</li>
    <li> <strong>NoSQL базы данных:</strong> Традиционные реляционные базы данных не всегда подходят для работы с большими объемами данных. NoSQL базы данных, такие как <strong>MongoDB</strong>, <strong>Cassandra</strong> и <strong>Redis</strong>, предлагают гибкие схемы и высокую производительность.</li>
    <li><strong>Data Warehousing:</strong> Хранилища данных (например, <strong>Amazon Redshift</strong>, <strong>Google BigQuery</strong>) позволяют хранить и анализировать большие объемы данных, обеспечивая быструю обработку запросов.</li>       
    </ol>
            </div>
        </Parallax>

        <Parallax>
            <div className="plush">
                <ul>
                <li>
                   <h2 id="section3" style={{textAlign:"center",  backgroundColor: highlightedSection ==='section3'? 'brown': 'transparent'}}>СЛОЖНОСТИ ПРИМЕНЕНИЯ BIG DATA</h2>
                </li>
              </ul>
                        <p id="section3" style={{textAlign:"center",  backgroundColor: highlightedSection ==='section3'? 'brown': 'transparent'}}>Применение технологий и методов обработки больших данных (<strong>Big Data</strong>) связано с рядом сложностей и вызовов. Большие данные требуют <u>инфраструктуру для хранения</u>. Часто под хранение данных выделяют отдельный <strong>центр обработки данных (ЦОД)</strong>. Но такие центры дорогие и требуют больших вложений.</p>
<p>Чтобы создать <strong>аналитическую модель</strong> (например, для обучения некоторых видов нейронных сетей), нужно очень много времени. Например, чтобы обучить современную нейронную сеть создавать изображения на основе текстового описания, используют массив данных размером <strong>270 терабайт</strong>. Обучение такой сети может занять около <strong>недели</strong>.</p>
<p>Знание технологий обработки больших данных очень важно, но также важно понимать нишу, где применяются <strong>big data</strong>. Иногда понять, <u>«что нужно?»</u>, сложнее, чем <u>«как это сделать?»</u>.</p>
<p>Данные могут поступать в различных форматах (<strong>структурированные</strong>, <strong>полу структурированные</strong> и <strong>неструктурированные</strong>). Это создает сложности в их интеграции и анализе. В некоторых приложениях, таких как <strong>финансовые рынки</strong> или <strong>системы мониторинга</strong>, требуется обработка данных в <strong>реальном времени</strong>. Это требует высокопроизводительных систем и алгоритмов, способных быстро реагировать на изменения.</p>
<p>Большие объемы данных часто содержат <strong>ошибки</strong>, <strong>дубликаты</strong> и <strong>пропуски</strong>. Обеспечение качества данных требует значительных усилий на этапе предобработки. Низкое качество данных может привести к неправильным выводам и решениям, что делает важным процесс <strong>очистки</strong> и <strong>валидации данных</strong>.</p>

            </div>
        </Parallax>

        <Parallax>
            <div className="plush">
                              <ul>
                <li>
                    <h2 style={{ textAlign: 'center' }}>Заключение</h2>
                </li>
                </ul>
          <p>
            Обработка больших данных открывает новые горизонты для бизнеса и
            науки, однако требует комплексного подхода к решению возникающих
            проблем. Понимание технологий, методов и вызовов, связанных с Big
            Data, является ключевым для успешного применения этих технологий.
            Важно не только знать, как обрабатывать данные, но и понимать, какие
            данные нужны для достижения конкретных целей.
          </p>

            </div>
        </Parallax>
      </div>
    </ParallaxProvider>
  );
};

export default ParallaxText;